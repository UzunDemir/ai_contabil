import os
import pickle
import hashlib
import streamlit as st
import requests
import numpy as np
from PyPDF2 import PdfReader
from datetime import datetime
from transformers import GPT2Tokenizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import logging

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
logging.basicConfig(level=logging.INFO)
CACHE_DIR = "cache"
DOCS_DIR = "docs"
os.makedirs(CACHE_DIR, exist_ok=True)
os.makedirs(DOCS_DIR, exist_ok=True)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
tokenizer = GPT2Tokenizer.from_pretrained("gpt2")

# API –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (–ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–æ –≤ –≥–ª–æ–±–∞–ª—å–Ω—É—é –æ–±–ª–∞—Å—Ç—å –≤–∏–¥–∏–º–æ—Å—Ç–∏)
api_key = st.secrets.get("DEEPSEEK_API_KEY")
if not api_key:
    st.error("API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–±–∞–≤—å—Ç–µ –µ–≥–æ –≤ Secrets.")
    st.stop()

url = "https://api.deepseek.com/v1/chat/completions"
headers = {
    "Authorization": f"Bearer {api_key}",
    "Content-Type": "application/json"
}

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Streamlit
st.set_page_config(layout="wide", initial_sidebar_state="auto")
st.markdown("""
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<style>
    .css-1jc7ptx, .e1ewe7hr3, .viewerBadge_container__1QSob, 
    .styles_viewerBadge__1yB5_, .viewerBadge_link__1S137, 
    .viewerBadge_text__1JaDK, #MainMenu, footer, header { 
        display: none !important; 
    }
    .center {
        display: flex;
        justify-content: center;
        align-items: center;
        text-align: center;
        flex-direction: column;
        margin-top: 0vh;
    }
</style>
""", unsafe_allow_html=True)

st.sidebar.title("–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞")
st.sidebar.title("TEST-passer (AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ —Ç–µ—Å—Ç–∞–º)")

class DocumentChunk:
    def __init__(self, text, doc_name, page_num):
        self.text = text
        self.doc_name = doc_name
        self.page_num = page_num

class KnowledgeBase:
    def __init__(self):
        self.chunks = []
        self.vectorizer = TfidfVectorizer(stop_words='english')
        self.tfidf_matrix = None
        self.doc_texts = []
        self.loaded_files = set()
    
    # ... (–æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∫–ª–∞—Å—Å–∞ KnowledgeBase –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
if 'knowledge_base' not in st.session_state:
    st.session_state.knowledge_base = KnowledgeBase()
    st.session_state.knowledge_base.load_with_cache()

if 'messages' not in st.session_state:
    st.session_state.messages = []

# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
if st.session_state.knowledge_base.loaded_files:
    st.subheader("üìö –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã:")
    for doc in sorted(st.session_state.knowledge_base.loaded_files):
        st.markdown(f"- {doc}")
else:
    st.warning("–í –ø–∞–ø–∫–µ docs –Ω–µ –Ω–∞–π–¥–µ–Ω–æ PDF-–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# –í–≤–æ–¥ –≤–æ–ø—Ä–æ—Å–∞
if prompt := st.chat_input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    relevant_chunks = st.session_state.knowledge_base.find_most_relevant_chunks(prompt)
    
    if not relevant_chunks:
        response_text = "–û—Ç–≤–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö ‚ùå"
        st.session_state.messages.append({"role": "assistant", "content": response_text})
        with st.chat_message("assistant"):
            st.markdown(response_text)
    else:
        context = "\n\n".join([f"–î–æ–∫—É–º–µ–Ω—Ç: {doc_name}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}\n{text}" 
                             for text, doc_name, page_num in relevant_chunks])
        
        full_prompt = f"""–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–∏–π —Å–æ–≤–µ—Ç–Ω–∏–∫.
        –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –ø–æ–Ω—è—Ç–Ω–æ –∏ —Å—Ç—Ä–æ–≥–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –∞–∫—Ç–æ–≤ (–≤–Ω–∏–∑—É —É–∫–∞–∑–∞–Ω—ã –∏—Å—Ç–æ—á–Ω–∏–∫–∏):

Question: {prompt}

Relevant materials:
{context}"""
        
        data = {
            "model": "deepseek-chat",
            "messages": [{"role": "user", "content": full_prompt}],
            "max_tokens": 2000,
            "temperature": 0.1
        }
        
        with st.spinner("–ò—â–µ–º –æ—Ç–≤–µ—Ç..."):
            start_time = datetime.now()
            
            try:
                response = requests.post(url, headers=headers, json=data)
                
                if response.status_code == 200:
                    response_data = response.json()
                    full_response = response_data['choices'][0]['message']['content']
                    
                    sources = "\n\n–ò—Å—Ç–æ—á–Ω–∏–∫–∏:\n" + "\n".join(
                        [f"- {doc_name}, —Å—Ç—Ä. {page_num}" for _, doc_name, page_num in relevant_chunks]
                    )
                    full_response += sources
                    
                    st.session_state.messages.append({"role": "assistant", "content": full_response})
                    with st.chat_message("assistant"):
                        st.markdown(full_response + " ‚úÖ")
                    
                    end_time = datetime.now()
                    duration = (end_time - start_time).total_seconds()
                    st.info(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {duration:.2f} —Å–µ–∫")
                else:
                    st.error(f"–û—à–∏–±–∫–∞ API: {response.status_code} - {response.text}")
            except Exception as e:
                st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}")
                logging.error(f"API request error: {str(e)}")

# –ö–Ω–æ–ø–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —á–∞—Ç–∞
if st.button("–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π"):
    st.session_state.messages = []
    st.rerun()

# –ö–Ω–æ–ø–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫—ç—à–∞
if st.button("–û–±–Ω–æ–≤–∏—Ç—å –∫—ç—à –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"):
    st.session_state.knowledge_base = KnowledgeBase()
    st.session_state.knowledge_base.load_with_cache()
    st.rerun()
